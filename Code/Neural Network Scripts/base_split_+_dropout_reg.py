# -*- coding: utf-8 -*-
"""base split + dropout/reg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P9nNxjTSpYPAauR6b5nJWNdd1AEHvOEa
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, Model, optimizers, regularizers
from keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, UpSampling2D, Activation, Flatten, Dense, MaxPooling2D, GroupNormalization
from keras.layers import Conv2DTranspose, Add, Reshape, Dropout, RandomFlip, RandomTranslation, RandomCrop, RandomRotation
from keras.models import Model

from keras.optimizers import Adam
import requests
from PIL import Image
import os
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split

# from keras.datasets import cifar10, mnist

def get_imgs(folder_path):

    # List all files in the folder
    file_names = os.listdir(folder_path)

    # Filter out only image files (assuming they have common image extensions)
    image_files = [f for f in file_names if f.endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif'))]

    image_files.sort()

    # Load images into a list
    images = []
    for image_file in image_files:
        image_path = os.path.join(folder_path, image_file)
        image = Image.open(image_path)
        images.append(np.array(image))

    images_array = np.stack(images)

    return images_array

!git clone https://github.com/marknader11/ultrasound_denoise.git

# Specify the folder containing the images
n = 255
clean_train = get_imgs('/content/ultrasound_denoise/proper split/clean_train')/n
clean_test = get_imgs('/content/ultrasound_denoise/proper split/clean_test')/n
clean_val = get_imgs('/content/ultrasound_denoise/proper split/clean_val')/n

noisy_train = get_imgs('/content/ultrasound_denoise/proper split/noisy_train')/n
noisy_test = get_imgs('/content/ultrasound_denoise/proper split/noisy_test')/n
noisy_val = get_imgs('/content/ultrasound_denoise/proper split/noisy_val')/n

# Now 'images_array' contains all the images from the folder
plt.figure(figsize=(15, 6))
for i in range(1, 6):
    plt.subplot(2, 5, i)
    plt.imshow(clean_train[i], cmap='gray')
    plt.axis('off')
    plt.subplot(2, 5, i+5)
    plt.imshow(noisy_train[i], cmap='gray')
    plt.axis('off')
plt.show()

def conv_block(x,layers,dropout_rate=0.2,reg_strength=0.005):
  x = Conv2D(layers, (3, 3), padding='same', kernel_regularizer=regularizers.l2(reg_strength))(x)
  x = GroupNormalization(groups=-1)(x)
  x = LeakyReLU(alpha=0.2)(x)
  x = Dropout(dropout_rate)(x)
  # x = BatchNormalization(momentum=0.8)(x)
  x = Conv2D(layers, (3, 3), padding='same', kernel_regularizer=regularizers.l2(reg_strength))(x)
  x = GroupNormalization(groups=-1)(x)
  x = LeakyReLU(alpha=0.2)(x)
  x = Dropout(dropout_rate)(x)
  # x = BatchNormalization(momentum=0.8)(x)

  return x

def de_conv_block(x,layers):
  x = Conv2DTranspose(layers, (4, 4), strides=(2, 2), padding='same')(x)
  x = LeakyReLU(alpha=0.2)(x)
  # x = BatchNormalization(momentum=0.8)(x)
  return x

def build_generator():
    input_img = Input((512,512, 1))

    # x = RandomFlip(mode='horizontal')(input_img)
    # x = RandomFlip(mode='vertical')(x)
    # x = RandomTranslation(0.1, 0.1)(x)
    # x = RandomRotation(0.1)(x)
    # x = RandomCrop(512, 512)(x)

    x = Reshape((512, 512, 1))(input_img)
    size = 64

    x = conv_block(x, int(size))
    skip1 = x
    x = MaxPooling2D(pool_size=(4, 4), strides=(2, 2), padding = 'same')(x)

    x = conv_block(x, int(size*2))
    skip2 = x
    x = MaxPooling2D(pool_size=(4, 4), strides=(2, 2), padding = 'same')(x)

    x = conv_block(x, int(size*4))
    skip3 = x
    x = MaxPooling2D(pool_size=(4, 4), strides=(2, 2), padding = 'same')(x)

    x = conv_block(x, int(size*8))
    skip4 = x
    x = MaxPooling2D(pool_size=(4, 4), strides=(2, 2), padding = 'same')(x)

    x = conv_block(x, int(size*16))

    x = de_conv_block(x, int(size*8))
    x = Add()([x, skip4])

    x = de_conv_block(x, int(size*4))
    x = Add()([x, skip3])

    x = de_conv_block(x, int(size*2))
    x = Add()([x, skip2])

    x = de_conv_block(x, int(size))
    x = Add()([x, skip1])

    x = Conv2D(1, (1, 1), padding='same')(x)
    # output_img = Activation('tanh')(x)

    return Model(input_img, x)

generator = build_generator()
generator.summary()



def ssim_metric(y_true, y_pred):
    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def PSNR_metric(y_true,y_pred,max_pixel=1.0):
    # Calculate Mean Squared Error (MSE)
    mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=[-3, -2, -1])

    # Handle potential division by zero
    mse = tf.maximum(mse, 1e-10)

    # Calculate PSNR
    # PSNR = 10 * log10((MAX^2) / MSE)
    psnr = 10.0 * tf.math.log(max_pixel**2 / mse) / tf.math.log(10.0)


    return tf.reduce_mean(psnr)

EPOCHS = 200
BATCH_SIZE = 10

generator = build_generator()
generator.compile(optimizer=Adam(), loss='mse', metrics=[ssim_metric])
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)


x_train = noisy_train #noisy data
y_train = clean_train #clean data

x_val = noisy_val #noisy data
y_val = clean_val #clean data

x_test = noisy_test #noisy data
y_test = clean_test #clean data

y_test  = tf.expand_dims(y_test, axis=-1)
y_train  = tf.expand_dims(y_train, axis=-1)
y_val  = tf.expand_dims(y_val, axis=-1)

generator.fit(x_train, y_train,
              validation_data=(x_val, y_val),
              batch_size=BATCH_SIZE,
              epochs=EPOCHS)
              # callbacks = [early_stopping])

tf.keras.backend.clear_session()

# tf.keras.backend.clear_session()

generator.save_weights('generator_weights.weights.h5')

# Test the generator with noisy test images
y_test  = tf.expand_dims(clean_test, axis=-1)
y_test = tf.cast(y_test, tf.float32)

x_test = tf.cast(noisy_test, tf.float32)
gen_test = generator.predict(noisy_test)

# Plot the results


# print('Baseline  SSIM is: ', ssim_metric(noisy_test, clean_test))
# print('Resulting SSIM is: ', ssim_metric(y_test, gen_test))
# print('')
# print('Baneline  PSNR is: ', PSNR_metric(x_test, clean_test))
# print('Resulting PSNR is: ', PSNR_metric(y_test, gen_test))
# print('')

mod = 0
plt.figure(figsize=(10, 6))
for i in range(1, 6):
    plt.subplot(3, 5, i)
    plt.imshow(clean_test[i+mod], cmap='gray')
    plt.axis('off')
    plt.subplot(3, 5, i+5)
    plt.imshow(noisy_test[i+mod], cmap='gray')
    plt.axis('off')
    plt.subplot(3, 5, i+10)
    plt.imshow(gen_test[i+mod], cmap='gray')
    plt.axis('off')
plt.show()

mod = 0
plt.figure(figsize=(10, 6))
for i in range(1, 6):
    plt.subplot(3, 5, i)
    plt.imshow(clean_test[i+mod], cmap='gray')
    plt.axis('off')
    plt.subplot(3, 5, i+5)
    plt.imshow(noisy_test[i+mod], cmap='gray')
    plt.axis('off')
    plt.subplot(3, 5, i+10)
    plt.imshow(gen_test[i+mod], cmap='gray')
    plt.axis('off')
plt.show()

ct_test_1 = Image.open('/content/sar.png').convert('L')
ct_test_1 = ct_test_1.resize((512, 512))
ct_test_1 = np.array(ct_test_1)
ct_test_1 = ct_test_1/n

ct_test_1 = tf.expand_dims(ct_test_1, axis=0)


us_test_1 = (generator(ct_test_1))
us_test_1 = tf.cast(us_test_1*255, tf.uint8)
us_test_1 = tf.squeeze(us_test_1)
us_test_1 = tf.expand_dims(us_test_1, axis=-1)
tf.io.write_file('sar.jpeg', tf.image.encode_jpeg(us_test_1, quality=100, format='grayscale'))
us_test_1 = tf.squeeze(us_test_1)


plt.imshow(us_test_1, cmap='gray')
plt.axis('off')

# save_path  = '/content/ultrasound_denoise/results/'
# if  not os.path.exists(save_path):
#   os.mkdir(save_path)
# save_folder = save_path + 'base_split_overfit/'
# if not os.path.exists(save_folder):
#   os.mkdir(save_folder)

# c_folder = save_folder + 'clean/'
# n_folder = save_folder + 'noisy/'
# g_folder = save_folder + 'gen/'

# if not os.path.exists(c_folder):
#   os.mkdir(c_folder)
# if not os.path.exists(n_folder):
#   os.mkdir(n_folder)
# if not os.path.exists(g_folder):
#   os.mkdir(g_folder)

# save_clean = tf.expand_dims(clean_test, axis=-1)
# save_noisy = tf.expand_dims(noisy_test, axis=-1)


# save_clean = tf.cast(save_clean*255, tf.uint8)
# save_noisy = tf.cast(save_noisy*255, tf.uint8)
# save_gen = tf.cast(gen_test*255, tf.uint8)




# for i in range(save_clean.shape[0]):
#   clean_img = tf.image.encode_jpeg(save_clean[i], quality=100, format='grayscale')
#   noisy_img = tf.image.encode_jpeg(save_noisy[i], quality=100, format='grayscale')
#   gen_img = tf.image.encode_jpeg(save_gen[i], quality=100, format='grayscale')

#   tf.io.write_file(c_folder + f'clean_img_{i}.jpeg',clean_img,)
#   tf.io.write_file(n_folder + f'noisy_img_{i}.jpeg',noisy_img)
#   tf.io.write_file(g_folder + f'gen_img_{i}.jpeg',gen_img)

# Commented out IPython magic to ensure Python compatibility.
def git_push():
  !git config --global user.name "marknader11"
  !git config --global user.email "mark.nader2000@gmail.com"
  !git remote set-url origin https://marknader11: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@github.com/marknader11/ultrasound_denoise.git

#   %cd /content/ultrasound_denoise/
#   %ls
  !git add .
  !git commit -m "added results base"
  !git push origin main
  !git push origin main

# git_push()